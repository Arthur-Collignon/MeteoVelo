{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-12-20T10:34:19.263830400Z",
     "start_time": "2025-12-20T10:34:19.078416Z"
    }
   },
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F\n",
    "import requests\n"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-20T10:34:40.917152100Z",
     "start_time": "2025-12-20T10:34:19.266295900Z"
    }
   },
   "cell_type": "code",
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Retrieve Bike Counting Data\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "MONTH = '04'\n",
    "YEAR = '2022'\n",
    "START_DATE = f'{YEAR}-{MONTH}-01'\n",
    "END_DATE = f'{YEAR}-{MONTH}-30'"
   ],
   "id": "783468df00c025e6",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Requête des données",
   "id": "5557c2a9ef97c466"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-20T10:34:42.979569700Z",
     "start_time": "2025-12-20T10:34:40.962271700Z"
    }
   },
   "cell_type": "code",
   "source": [
    "channels_data = spark.read.option(\"header\", \"true\") \\\n",
    "               .option(\"sep\", \";\") \\\n",
    "               .csv(\"./CSVs/channels.csv\")\n",
    "\n",
    "channels_ID = [row['channel_id'] for row in channels_data.collect()]"
   ],
   "id": "e607fe0d98606298",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-20T10:34:43.002281200Z",
     "start_time": "2025-12-20T10:34:42.992397700Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def request_counting_data(channel_id, start_date, end_date):\n",
    "    url = f'https://data.grandlyon.com/fr/datapusher/ws/timeseries/pvo_patrimoine_voirie.pvocomptagemeasure/all.json?start_datetime__gte={start_date}&start_datetime__lt={end_date}&channel_id__eq={channel_id}&maxfeatures=-1'\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        if response.status_code == 200:\n",
    "            return response.json().get('values', [])\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to retrieve data for channel {channel_id}: {e}\")\n",
    "        return []\n",
    "\n",
    "def request_temp_data(start_date, end_date):\n",
    "    url = f'https://data.grandlyon.com/fr/datapusher/ws/timeseries/biotope.temperature/all.json?horodate__gte={start_date}&horodate__lt={end_date}&maxfeatures=-1'\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        if response.status_code == 200:\n",
    "            return response.json().get('values', [])\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to retrieve temperature data: {e}\")\n",
    "        return []\n",
    "\n",
    "def request_rain_data(start_date, end_date):\n",
    "    url = f'https://data.grandlyon.com/fr/datapusher/ws/timeseries/eau.pluviometrie_mesure/all.json?maxfeatures=-1&horodate__gte={start_date}&horodate__lte={end_date}'\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        if response.status_code == 200:\n",
    "            return response.json().get('values', [])\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to retrieve rainfall data: {e}\")\n",
    "        return []"
   ],
   "id": "93c37c3321137143",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Traitement des données",
   "id": "9a25345b1480af6e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Traitement des données de comptage",
   "id": "86c426feab5b2bd"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-20T10:34:43.021527200Z",
     "start_time": "2025-12-20T10:34:43.012768300Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Aggréger les données de comptage de la même heure toutes stations confondues\n",
    "def traitement_count_data(data):\n",
    "    data_with_hour = data.withColumn(\"start_datetime\", F.date_trunc(\"hour\", F.col(\"start_datetime\")))\n",
    "    count_data_agg = data_with_hour.groupBy(\"start_datetime\") \\\n",
    "        .agg(F.sum(\"count\").alias(\"total_count\")) \\\n",
    "        .orderBy(\"start_datetime\")\n",
    "    count_data_agg.drop(\"end_datetime\")\n",
    "    count_data_agg = count_data_agg.withColumnRenamed(\"start_datetime\", \"horodate_heure\")\n",
    "    return count_data_agg"
   ],
   "id": "a0ae33d43e769f15",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Traitement des données de température",
   "id": "392998cd5dffd4e6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-20T10:34:43.029488100Z",
     "start_time": "2025-12-20T10:34:43.022921500Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Aggréger les données de température par horodate selon l'heure et la station de mesure\n",
    "def traitement_temp_data(data):\n",
    "    data_with_hour = data.withColumn(\"horodate_heure\", F.date_trunc(\"hour\", F.col(\"horodate\")))\n",
    "    temp_data_agg = data_with_hour.groupBy(\"horodate_heure\") \\\n",
    "        .agg(F.avg(\"degre_celsius\").alias(\"avg_temp_per_hour\")) \\\n",
    "        .orderBy(\"horodate_heure\")\n",
    "    temp_data_agg.drop(\"horodate\")\n",
    "    return temp_data_agg"
   ],
   "id": "309b4e4580a06b48",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Traitement des données de précipitations",
   "id": "9747039d87187a2f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-20T10:34:43.037297900Z",
     "start_time": "2025-12-20T10:34:43.030496100Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Aggréger les données de précipitations d'une même station de mesure\n",
    "def traitement_rainfall(data):\n",
    "    data_with_hour = data.withColumn(\"horodate_heure\", F.date_trunc(\"hour\", F.col(\"horodate\")))\n",
    "    rain_data_agg_station = data_with_hour.groupBy(\"horodate_heure\", \"identifiant\") \\\n",
    "        .agg(F.sum(\"pluie_mm\").alias(\"avg_pluie_per_station_per_hour\"))\n",
    "    rain_data_agg = rain_data_agg_station.groupBy(\"horodate_heure\") \\\n",
    "        .agg(F.avg(\"avg_pluie_per_station_per_hour\").alias(\"avg_pluie_per_hour\")) \\\n",
    "        .orderBy(\"horodate_heure\")\n",
    "    rain_data_agg.drop(\"horodate\")\n",
    "    return rain_data_agg\n"
   ],
   "id": "a25fd3f8ef3176d7",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Exécution du traitement",
   "id": "d5a5e4b432ac1691"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-20T10:35:12.731163400Z",
     "start_time": "2025-12-20T10:34:43.038392500Z"
    }
   },
   "cell_type": "code",
   "source": [
    "count_rdd_ids = spark.sparkContext.parallelize(channels_ID)\n",
    "count_records_rdd = count_rdd_ids.flatMap(lambda cid: request_counting_data(cid, START_DATE, END_DATE))\n",
    "count_data_spark = spark.createDataFrame(count_records_rdd)\n",
    "aggregated_count_data = traitement_count_data(count_data_spark)\n",
    "aggregated_count_data.show()"
   ],
   "id": "8c3bcff98d33127d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-----------+\n",
      "|     horodate_heure|total_count|\n",
      "+-------------------+-----------+\n",
      "|2022-03-31 23:00:00|       3607|\n",
      "|2022-04-01 00:00:00|       1762|\n",
      "|2022-04-01 01:00:00|       1207|\n",
      "|2022-04-01 02:00:00|        878|\n",
      "|2022-04-01 03:00:00|        652|\n",
      "|2022-04-01 04:00:00|        885|\n",
      "|2022-04-01 05:00:00|       2315|\n",
      "|2022-04-01 06:00:00|       9696|\n",
      "|2022-04-01 07:00:00|      21176|\n",
      "|2022-04-01 08:00:00|      11340|\n",
      "|2022-04-01 09:00:00|       6401|\n",
      "|2022-04-01 10:00:00|       7415|\n",
      "|2022-04-01 11:00:00|      11734|\n",
      "|2022-04-01 12:00:00|      10602|\n",
      "|2022-04-01 13:00:00|       8518|\n",
      "|2022-04-01 14:00:00|       8810|\n",
      "|2022-04-01 15:00:00|      13040|\n",
      "|2022-04-01 16:00:00|      20039|\n",
      "|2022-04-01 17:00:00|      18692|\n",
      "|2022-04-01 18:00:00|      14181|\n",
      "+-------------------+-----------+\n",
      "only showing top 20 rows\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-20T10:35:29.905699400Z",
     "start_time": "2025-12-20T10:35:12.793017700Z"
    }
   },
   "cell_type": "code",
   "source": [
    "temp_records = request_temp_data(START_DATE, END_DATE)\n",
    "temp_data_spark = spark.createDataFrame(temp_records)\n",
    "aggregated_temp_data = traitement_temp_data(temp_data_spark)\n",
    "aggregated_temp_data = aggregated_temp_data.withColumn(\"avg_temp_per_hour\", F.round(F.col(\"avg_temp_per_hour\"), 2))\n",
    "aggregated_temp_data.show()"
   ],
   "id": "25afbf9c49f31a3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-----------------+\n",
      "|     horodate_heure|avg_temp_per_hour|\n",
      "+-------------------+-----------------+\n",
      "|2022-03-31 23:00:00|              7.4|\n",
      "|2022-04-01 00:00:00|             6.96|\n",
      "|2022-04-01 01:00:00|             6.49|\n",
      "|2022-04-01 02:00:00|             4.51|\n",
      "|2022-04-01 03:00:00|              2.7|\n",
      "|2022-04-01 04:00:00|             2.11|\n",
      "|2022-04-01 05:00:00|             1.55|\n",
      "|2022-04-01 06:00:00|             1.37|\n",
      "|2022-04-01 07:00:00|             1.51|\n",
      "|2022-04-01 08:00:00|             1.86|\n",
      "|2022-04-01 09:00:00|             2.14|\n",
      "|2022-04-01 10:00:00|             2.29|\n",
      "|2022-04-01 11:00:00|             2.44|\n",
      "|2022-04-01 12:00:00|             2.47|\n",
      "|2022-04-01 13:00:00|              2.5|\n",
      "|2022-04-01 14:00:00|             2.54|\n",
      "|2022-04-01 15:00:00|             3.38|\n",
      "|2022-04-01 16:00:00|             3.88|\n",
      "|2022-04-01 17:00:00|             4.07|\n",
      "|2022-04-01 18:00:00|             3.88|\n",
      "+-------------------+-----------------+\n",
      "only showing top 20 rows\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-20T10:35:46.028718Z",
     "start_time": "2025-12-20T10:35:29.968808100Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Partie Meteo\n",
    "rain_records = request_rain_data(START_DATE, END_DATE)\n",
    "rain_data_spark = spark.createDataFrame(rain_records)\n",
    "aggregated_rain_data = traitement_rainfall(rain_data_spark)\n",
    "aggregated_rain_data = aggregated_rain_data.withColumn(\"avg_pluie_per_hour\", F.round(F.col(\"avg_pluie_per_hour\"), 2))\n",
    "aggregated_rain_data.show()"
   ],
   "id": "fcbd0ccc99887d55",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+------------------+\n",
      "|     horodate_heure|avg_pluie_per_hour|\n",
      "+-------------------+------------------+\n",
      "|2022-03-31 23:00:00|               0.1|\n",
      "|2022-04-01 01:00:00|               0.2|\n",
      "|2022-04-01 02:00:00|              0.75|\n",
      "|2022-04-01 03:00:00|              1.18|\n",
      "|2022-04-01 04:00:00|               1.3|\n",
      "|2022-04-01 05:00:00|              1.53|\n",
      "|2022-04-01 06:00:00|              1.07|\n",
      "|2022-04-01 07:00:00|               0.6|\n",
      "|2022-04-01 08:00:00|              0.32|\n",
      "|2022-04-01 09:00:00|              1.04|\n",
      "|2022-04-01 10:00:00|              0.93|\n",
      "|2022-04-01 11:00:00|              0.53|\n",
      "|2022-04-01 12:00:00|               0.4|\n",
      "|2022-04-01 13:00:00|               0.2|\n",
      "|2022-04-01 14:00:00|              0.45|\n",
      "|2022-04-01 15:00:00|              1.95|\n",
      "|2022-04-01 18:00:00|              0.32|\n",
      "|2022-04-01 19:00:00|               0.3|\n",
      "|2022-04-01 20:00:00|              0.95|\n",
      "|2022-04-01 21:00:00|              1.09|\n",
      "+-------------------+------------------+\n",
      "only showing top 20 rows\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-20T10:36:29.921320800Z",
     "start_time": "2025-12-20T10:35:46.059687600Z"
    }
   },
   "cell_type": "code",
   "source": [
    "final_data = aggregated_count_data.join(aggregated_temp_data, \"horodate_heure\", \"left\") \\\n",
    "                                  .join(aggregated_rain_data, \"horodate_heure\", \"left\") \\\n",
    "                                  .withColumnRenamed(\"horodate_heure\", \"datetime\") \\\n",
    "                                  .orderBy(\"datetime\")\n",
    "final_data = final_data.fillna(0)\n",
    "final_data.show()"
   ],
   "id": "7781669ef042c4da",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-----------+-----------------+------------------+\n",
      "|           datetime|total_count|avg_temp_per_hour|avg_pluie_per_hour|\n",
      "+-------------------+-----------+-----------------+------------------+\n",
      "|2022-03-31 23:00:00|       3607|              7.4|               0.1|\n",
      "|2022-04-01 00:00:00|       1762|             6.96|               0.0|\n",
      "|2022-04-01 01:00:00|       1207|             6.49|               0.2|\n",
      "|2022-04-01 02:00:00|        878|             4.51|              0.75|\n",
      "|2022-04-01 03:00:00|        652|              2.7|              1.18|\n",
      "|2022-04-01 04:00:00|        885|             2.11|               1.3|\n",
      "|2022-04-01 05:00:00|       2315|             1.55|              1.53|\n",
      "|2022-04-01 06:00:00|       9696|             1.37|              1.07|\n",
      "|2022-04-01 07:00:00|      21176|             1.51|               0.6|\n",
      "|2022-04-01 08:00:00|      11340|             1.86|              0.32|\n",
      "|2022-04-01 09:00:00|       6401|             2.14|              1.04|\n",
      "|2022-04-01 10:00:00|       7415|             2.29|              0.93|\n",
      "|2022-04-01 11:00:00|      11734|             2.44|              0.53|\n",
      "|2022-04-01 12:00:00|      10602|             2.47|               0.4|\n",
      "|2022-04-01 13:00:00|       8518|              2.5|               0.2|\n",
      "|2022-04-01 14:00:00|       8810|             2.54|              0.45|\n",
      "|2022-04-01 15:00:00|      13040|             3.38|              1.95|\n",
      "|2022-04-01 16:00:00|      20039|             3.88|               0.0|\n",
      "|2022-04-01 17:00:00|      18692|             4.07|               0.0|\n",
      "|2022-04-01 18:00:00|      14181|             3.88|              0.32|\n",
      "+-------------------+-----------+-----------------+------------------+\n",
      "only showing top 20 rows\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-20T10:42:07.158403400Z",
     "start_time": "2025-12-20T10:41:15.993098400Z"
    }
   },
   "cell_type": "code",
   "source": [
    "final_data.write \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .option(\"sep\", \";\") \\\n",
    "    .csv(f\"./CSVs/spark/counting_data_{MONTH}_{YEAR}\")"
   ],
   "id": "a5ffbf3bcdcac4e7",
   "outputs": [],
   "execution_count": 15
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

# Plan Machine Learning - MeteoVelo

## ğŸ¯ Objectif
CrÃ©er un modÃ¨le prÃ©dictif pour estimer le volume de cyclistes en fonction des conditions mÃ©tÃ©orologiques et temporelles.

---

## ğŸ“‹ Ã‰tape 1: Exploration des DonnÃ©es (EDA)

### 1.1 Chargement et Inspection
- [ ] Charger les 3 datasets:
  - `counting_data_april_2022.csv` (donnÃ©es vÃ©lo)
  - `temperature_converted.csv` (tempÃ©ratures)
  - `eau_converted.csv` (pluviomÃ©trie)
- [ ] VÃ©rifier la structure de chaque dataset
- [ ] Identifier les colonnes clÃ©s pour la fusion
- [ ] Analyser les types de donnÃ©es et formats de dates

### 1.2 Analyse QualitÃ© des DonnÃ©es
- [ ] DÃ©tecter les valeurs manquantes (NaN)
- [ ] Identifier les valeurs aberrantes (outliers)
- [ ] VÃ©rifier la cohÃ©rence temporelle
- [ ] Analyser la distribution des variables

### 1.3 Visualisations Exploratoires
- [ ] Distribution du nombre de vÃ©los par heure/jour
- [ ] Distribution de la tempÃ©rature
- [ ] Distribution des prÃ©cipitations
- [ ] Patterns temporels (tendances jour/semaine)

---

## ğŸ“Š Ã‰tape 2: PrÃ©paration et Fusion des DonnÃ©es

### 2.1 PrÃ©traitement des DonnÃ©es VÃ©lo
- [ ] Convertir les dates au bon format (datetime)
- [ ] AgrÃ©ger les comptages par pÃ©riode (heure/jour)
- [ ] GÃ©rer les valeurs manquantes (interpolation ou suppression)
- [ ] CrÃ©er une variable cible: `nb_velos_total`

### 2.2 PrÃ©traitement des DonnÃ©es MÃ©tÃ©o
- [ ] Harmoniser les timestamps (mÃªme format que les donnÃ©es vÃ©lo)
- [ ] GÃ©rer les valeurs manquantes mÃ©tÃ©o
- [ ] VÃ©rifier la cohÃ©rence des mesures (pas de tempÃ©ratures impossibles)

### 2.3 Fusion des Datasets
- [ ] Merger les donnÃ©es vÃ©lo + tempÃ©rature (sur timestamp)
- [ ] Merger avec les donnÃ©es de pluviomÃ©trie
- [ ] VÃ©rifier l'intÃ©gritÃ© aprÃ¨s fusion
- [ ] CrÃ©er le dataset final `data_merged.csv`

**RÃ©sultat attendu:** Un dataset unique avec colonnes:
- `timestamp` (datetime)
- `nb_velos` (target)
- `temperature` (Â°C)
- `precipitation` (mm)
- + autres features mÃ©tÃ©o si disponibles

---

## ğŸ”§ Ã‰tape 3: Feature Engineering

### 3.1 Features Temporelles
- [ ] `hour` : Heure de la journÃ©e (0-23)
- [ ] `day_of_week` : Jour de la semaine (0=Lundi, 6=Dimanche)
- [ ] `is_weekend` : BoolÃ©en (Samedi/Dimanche)
- [ ] `month` : Mois (1-12)
- [ ] `is_rush_hour` : BoolÃ©en (7-9h et 17-19h)

### 3.2 Features MÃ©tÃ©o Enrichies
- [ ] `temp_category` : CatÃ©gories (froid < 5Â°C, doux 5-15Â°C, chaud > 15Â°C)
- [ ] `is_raining` : BoolÃ©en (prÃ©cipitations > 0)
- [ ] `rain_intensity` : CatÃ©gories (faible/modÃ©rÃ©e/forte)

### 3.3 Features Calendaires (optionnel mais recommandÃ©)
- [ ] `is_holiday` : Jours fÃ©riÃ©s franÃ§ais
- [ ] `is_school_vacation` : Vacances scolaires zone A (Lyon)

### 3.4 Encodage des Variables CatÃ©gorielles
- [ ] One-Hot Encoding pour `day_of_week`, `month`, etc.
- [ ] Label Encoding si nÃ©cessaire

---

## ğŸ¤– Ã‰tape 4: ModÃ©lisation

### 4.1 PrÃ©paration des DonnÃ©es
- [ ] SÃ©parer Features (X) et Target (y)
- [ ] Train/Test Split (80/20 ou 70/30)
  - Option 1: Split alÃ©atoire
  - Option 2: Split temporel (les 24 premiers jours pour train, les 6 derniers pour test)
- [ ] Normalisation/Standardisation des features numÃ©riques (si nÃ©cessaire)

### 4.2 ModÃ¨le Baseline: RÃ©gression LinÃ©aire
- [ ] EntraÃ®ner une rÃ©gression linÃ©aire simple
- [ ] PrÃ©dire sur l'ensemble de test
- [ ] Calculer les mÃ©triques:
  - MAE (Mean Absolute Error)
  - RMSE (Root Mean Squared Error)
  - RÂ² Score
- [ ] Analyser les coefficients (importance des features)

### 4.3 ModÃ¨le AvancÃ©: Random Forest
- [ ] EntraÃ®ner un Random Forest Regressor
- [ ] Tester diffÃ©rents hyperparamÃ¨tres:
  - `n_estimators` (nombre d'arbres: 50, 100, 200)
  - `max_depth` (profondeur max: None, 10, 20)
  - `min_samples_split` (2, 5, 10)
- [ ] Utiliser GridSearchCV ou RandomizedSearchCV pour l'optimisation
- [ ] Calculer les mÃªmes mÃ©triques que pour la baseline

### 4.4 ModÃ¨les SupplÃ©mentaires (optionnel)
- [ ] XGBoost (si temps disponible)
- [ ] Gradient Boosting (si temps disponible)

---

## ğŸ“ˆ Ã‰tape 5: Ã‰valuation et Analyse

### 5.1 Comparaison des ModÃ¨les
- [ ] Tableau comparatif des mÃ©triques (MAE, RMSE, RÂ²)
- [ ] Graphiques: PrÃ©dictions vs Valeurs RÃ©elles
- [ ] Analyse des rÃ©sidus (erreurs)

### 5.2 Importance des Features
- [ ] Feature Importance du Random Forest
- [ ] Identifier les variables les plus impactantes:
  - MÃ©tÃ©o (tempÃ©rature, pluie) vs Temporelles (heure, jour)

### 5.3 InterprÃ©tation MÃ©tier
- [ ] Quantifier l'impact de la pluie (% de baisse)
- [ ] Quantifier l'impact de la tempÃ©rature
- [ ] Identifier les heures de pointe
- [ ] Identifier les jours avec le plus de cyclistes

---

## ğŸ“Š Ã‰tape 6: Visualisations et Insights

### 6.1 Graphiques ClÃ©s
- [ ] CorrÃ©lation Heatmap (toutes les variables)
- [ ] Impact de la pluie sur le trafic (bar plot)
- [ ] Impact de la tempÃ©rature (scatter plot)
- [ ] PrÃ©dictions vs RÃ©alitÃ© (ligne temporelle)
- [ ] Feature Importance (bar plot)

### 6.2 Insights Business
- [ ] RÃ©diger 3-5 insights clÃ©s pour les dÃ©cideurs
  - Ex: "La pluie rÃ©duit le trafic vÃ©lo de X%"
  - Ex: "Les heures de pointe sont 8h et 18h"
  - Ex: "La tempÃ©rature optimale est entre X et YÂ°C"

---

## ğŸš€ Ã‰tape 7: Sauvegarde et Documentation

### 7.1 Sauvegarder les RÃ©sultats
- [ ] Exporter le dataset final: `data_merged.csv`
- [ ] Sauvegarder le meilleur modÃ¨le: `model_final.pkl` (joblib)
- [ ] CrÃ©er un fichier de rÃ©sultats: `results.json` avec les mÃ©triques

### 7.2 Notebook Final
- [ ] Organiser le notebook en sections claires
- [ ] Ajouter des commentaires et markdown explicatifs
- [ ] Nettoyer le code (supprimer les cellules inutiles)
- [ ] VÃ©rifier que tout est reproductible

### 7.3 Documentation
- [ ] README.md ou rapport final avec:
  - MÃ©thodologie
  - RÃ©sultats principaux
  - Graphiques clÃ©s
  - Conclusions

---

## ğŸ› ï¸ Technologies et BibliothÃ¨ques

```python
# Data manipulation
import pandas as pd
import numpy as np

# Visualization
import matplotlib.pyplot as plt
import seaborn as sns

# Machine Learning
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.linear_model import LinearRegression
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
from sklearn.preprocessing import StandardScaler

# Sauvegarde
import joblib
import json
```

---

## ğŸ“… Ordre de PrioritÃ©

1. **Phase 1 (Fondations):** Ã‰tapes 1 + 2 â†’ Avoir un dataset propre et fusionnÃ©
2. **Phase 2 (Features):** Ã‰tape 3 â†’ CrÃ©er les features temporelles et mÃ©tÃ©o
3. **Phase 3 (ModÃ¨les):** Ã‰tape 4.1 + 4.2 â†’ Baseline fonctionnelle
4. **Phase 4 (AmÃ©lioration):** Ã‰tape 4.3 â†’ Random Forest optimisÃ©
5. **Phase 5 (Finalisation):** Ã‰tapes 5 + 6 + 7 â†’ Analyse et documentation

---

## âœ… CritÃ¨res de SuccÃ¨s

- [ ] Dataset fusionnÃ© propre et exploitable
- [ ] Au moins 2 modÃ¨les fonctionnels (Linear + Random Forest)
- [ ] RÂ² > 0.6 sur l'ensemble de test
- [ ] Insights mÃ©tier clairs et visualisÃ©s
- [ ] Code propre et reproductible

---

## ğŸ’¡ Questions Ã  RÃ©soudre en Cours de Route

1. Quel pas de temps utiliser? (heure vs jour)
2. Comment gÃ©rer les compteurs multiples? (agrÃ©gation spatiale)
3. Faut-il normaliser les features?
4. Train/Test split alÃ©atoire ou temporel?
5. Quelles sont les features les plus importantes?

---

**PrÃªt Ã  dÃ©marrer!** ğŸš´â€â™‚ï¸
